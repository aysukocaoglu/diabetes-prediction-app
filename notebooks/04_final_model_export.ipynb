{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05bd8886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# ML & Metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e48e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"../data/diabetes.csv\")\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f82ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81        99\n",
      "           1       0.66      0.67      0.67        55\n",
      "\n",
      "    accuracy                           0.76       154\n",
      "   macro avg       0.74      0.74      0.74       154\n",
      "weighted avg       0.76      0.76      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best hyperparameters\n",
    "final_model = LogisticRegression(C=10.0, solver='liblinear', max_iter=1000)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9cc3fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final model saved as 'final_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Save the model\n",
    "with open(\"../models/final_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_model, f)\n",
    "\n",
    "print(\"‚úÖ Final model saved as 'final_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d280e32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 01:41:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final model logged to MLflow.\n",
      "üèÉ View run final_model at: http://127.0.0.1:5000/#/experiments/0/runs/aa647d3130204af480daaa4129306f1c\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"final_model\"):\n",
    "    mlflow.log_param(\"C\", 10)\n",
    "    mlflow.log_param(\"solver\", \"liblinear\")\n",
    "\n",
    "    mlflow.sklearn.log_model(final_model, \"model\")\n",
    "    print(\"‚úÖ Final model logged to MLflow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "95eb7a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 01:41:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'DiabetesPredictionModel' already exists. Creating a new version of this model...\n",
      "2025/04/23 01:41:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: DiabetesPredictionModel, version 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Final model logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '11' of model 'DiabetesPredictionModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered model: DiabetesPredictionModel (version 11)\n",
      "üèÉ View run final_model at: http://127.0.0.1:5000/#/experiments/0/runs/64ff6172814b4a5397583115971da20f\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"final_model\") as run:\n",
    "    mlflow.log_param(\"C\", 10)\n",
    "    mlflow.log_param(\"solver\", \"liblinear\")\n",
    "    \n",
    "    final_model.fit(X_train, y_train)\n",
    "    y_pred = final_model.predict(X_test)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "    mlflow.sklearn.log_model(final_model, \"model\")\n",
    "    print(\"‚úÖ Final model logged to MLflow.\")\n",
    "\n",
    "    # üîê Model Registry \n",
    "    import time\n",
    "    from mlflow.tracking import MlflowClient\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    model_name = \"DiabetesPredictionModel\"\n",
    "\n",
    "    client = MlflowClient()\n",
    "    result = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "    time.sleep(5)\n",
    "    print(f\"‚úÖ Registered model: {model_name} (version {result.version})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b3719606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aysuk\\AppData\\Local\\Temp\\ipykernel_30324\\80303946.py:9: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model 'DiabetesPredictionModel' version 11 moved to Production stage.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "model_name = \"DiabetesPredictionModel\"\n",
    "version = 11\n",
    "\n",
    "# Stage to Production\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True \n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model '{model_name}' version {version} moved to Production stage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7a4f87d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prediction: {'predictions': [1]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"http://127.0.0.1:5001/invocations\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        [6, 148, 72, 35, 0, 33.6, 0.627, 50]  \n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "print(\"‚úÖ Prediction:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "874fe60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simulated monitoring metrics have been logged to MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Simulate performance monitoring over time\n",
    "# At each step, sample a different subset of the test data\n",
    "for step in range(5):\n",
    "    # Randomly sample 50 test instances (without replacement)\n",
    "    X_sample, y_sample = resample(X_test, y_test, n_samples=50, random_state=step)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = final_model.predict(X_sample)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_sample, y_pred)\n",
    "    f1 = f1_score(y_sample, y_pred)\n",
    "    \n",
    "    # Log the metrics to MLflow with a time step\n",
    "    mlflow.log_metric(\"simulated_accuracy\", acc, step=step)\n",
    "    mlflow.log_metric(\"simulated_f1_score\", f1, step=step)\n",
    "\n",
    "print(\"‚úÖ Simulated monitoring metrics have been logged to MLflow.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
